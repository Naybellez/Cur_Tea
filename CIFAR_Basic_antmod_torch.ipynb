{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naybellez/Cur_Tea/blob/main/CIFAR_Basic_antmod_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4a1aeb00",
      "metadata": {
        "id": "4a1aeb00"
      },
      "outputs": [],
      "source": [
        "# the most basic CNN built in torch. \n",
        "# to be trained on CIFAR-10\n",
        "# 100523"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "692f265c",
      "metadata": {
        "id": "692f265c"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "import cv2\n",
        "from torch.nn import functional\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "\n",
        "random_seed = random.seed()\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(X_train, y_train,\n",
        "                                                  test_size = 0.1, train_size=0.9,\n",
        "                                      random_state=random_seed, shuffle = True)"
      ],
      "metadata": {
        "id": "igJQzc8bvt09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "652447ea-06f9-4642-f331-28da97e916f6"
      },
      "id": "igJQzc8bvt09",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 12s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('train: ', len(x_train), len(y_train))\n",
        "print('val: ', len(x_val), len(y_val))\n",
        "print('test: ', len(x_train), len(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IrnlRz9xpnS",
        "outputId": "37c27981-c698-4f37-bd93-b493dbf1eb9e"
      },
      "id": "-IrnlRz9xpnS",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train:  45000 45000\n",
            "val:  5000 5000\n",
            "test:  45000 45000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def label_dist_plot(data, label):\n",
        "  plt.figure()\n",
        "  _, _, _ = plt.hist(data, bins=[0, 1, 2,3,4,5,6,7,8,9,10], align='left')\n",
        "  plt.xticks(np.unique(data))\n",
        "  plt.xlim(left=min(np.unique(data))-1, right=max(np.unique(data))+1)\n",
        "  plt.title(label)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "label_dist_plot(y_train, 'Training labels')\n",
        "label_dist_plot(y_test, 'Test labels')\n",
        "label_dist_plot(y_val, 'validation labels')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ravdhjoZyNpJ",
        "outputId": "f36e0f78-7558-4077-b4c5-71b6b745f8be"
      },
      "id": "ravdhjoZyNpJ",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# look at imgs\n",
        "\n",
        "for i in range(9):  \n",
        "  plt.subplot(330 + 1 + i)\n",
        "  plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tOS652vKynQo",
        "outputId": "c4d53aca-c6d5-4d84-a562-dd2ca0d40c96"
      },
      "id": "tOS652vKynQo",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check shape of imgs\n",
        "\n",
        "print('image shape: ', x_train[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ck3uTiRv2X9Q",
        "outputId": "60454c61-7827-40d2-edcb-691abe38d779"
      },
      "id": "ck3uTiRv2X9Q",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image shape:  (32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oDdCf8K2GOv",
        "outputId": "cff73da4-6454-4773-8300-e3341f000c6c"
      },
      "id": "0oDdCf8K2GOv",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VxyS7QXz2W8f"
      },
      "id": "VxyS7QXz2W8f",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "            \"\"\"nn.Conv2d(3, out_channels=9, kernel_size=3, padding=2),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Dropout(p=0.3),\n",
        "            nn.Conv2d(9, 64, kernel_size=3, padding=1),\"\"\""
      ],
      "metadata": {
        "id": "AmAT9dK5S2p3"
      },
      "id": "AmAT9dK5S2p3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "2592/12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpDEEG61TRWW",
        "outputId": "995dcf2a-bb33-4f17-ee13-27e1e3ca399b"
      },
      "id": "cpDEEG61TRWW",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "216.0"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "\n",
        "class basicTorchNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(basicTorchNet, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.conv_layers = nn.Sequential(  #weight of size [1, 100, 3], expected input[1, 34, 34] to have 100 channels\n",
        "              nn.Conv2d(in_channels=3, out_channels=9, kernel_size=3, padding=2), \n",
        "              nn.Conv1d(in_channels=34, out_channels=9, kernel_size=3), #mat1 and mat2 shapes cannot be multiplied (1x32 and 8400x10)\n",
        "              nn.ReLU(inplace=True),\n",
        "          )\n",
        "\n",
        "        \n",
        "        self.linear_1 = nn.Sequential( #torch.Size([1, 100, 24])\n",
        "            nn.Linear(2592, 10), #   (1x2592 and 216x10)\n",
        "            nn.ReLU(),\n",
        "  \n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "      #forward method. opposition to backward pass\n",
        "        x= self.conv_layers(x)\n",
        "        #print('conv x', x)\n",
        "        x = x.flatten()\n",
        "        x = x.squeeze()\n",
        "        #print('conv x2', x)\n",
        "        x = self.linear_1(x)\n",
        "        #print('lin1 x', x)\n",
        "        return x\n",
        "        \n",
        "\n",
        "model = basicTorchNet().to(device)\n",
        "print(model)\n",
        "\n",
        "#conv1d() received an invalid combination of arguments - got (numpy.ndarray, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n",
        " #* (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcny-86Q19lZ",
        "outputId": "15b7f1e2-ab9f-48ad-9faa-d1cdfc379b1f"
      },
      "id": "vcny-86Q19lZ",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "basicTorchNet(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (conv_layers): Sequential(\n",
            "    (0): Conv2d(3, 9, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (1): Conv1d(34, 9, kernel_size=(3,), stride=(1,))\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (linear_1): Sequential(\n",
            "    (0): Linear(in_features=2592, out_features=10, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#each back propagartion, shows which layres have highest gradients. grafients av over neurons/layre\n",
        "def plot_grad_flow(named_parameters):\n",
        "    ave_grads = []\n",
        "    layers = []\n",
        "    for n, p in named_parameters:\n",
        "        if(p.requires_grad) and (\"bias\" not in n):\n",
        "            layers.append(n)\n",
        "            ave_grads.append(p.grad.abs().mean())\n",
        "    plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
        "    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n",
        "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
        "    plt.xlim(xmin=0, xmax=len(ave_grads))\n",
        "    plt.xlabel(\"Layers\")\n",
        "    plt.ylabel(\"average gradient\")\n",
        "    plt.title(\"Gradient flow\")\n",
        "    plt.grid(True)"
      ],
      "metadata": {
        "id": "bKLDkxox4-p1"
      },
      "id": "bKLDkxox4-p1",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensoring(input):\n",
        "\n",
        "        img_tensor = torch.tensor(input)\n",
        "        img_tensor = img_tensor.to(torch.float32)\n",
        "        img_tensor = functional.normalize(img_tensor)\n",
        "        img_tensor = torch.reshape(img_tensor, [3,32, 32])\n",
        "\n",
        "        return img_tensor\n"
      ],
      "metadata": {
        "id": "3slESV6b91i-"
      },
      "id": "3slESV6b91i-",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Loss \n",
        "loss_fn = nn.MSELoss() #mean2 error. #nn.CrossEntropyLoss() #normalising, probability\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "Orm4p6JN5e_F"
      },
      "id": "Orm4p6JN5e_F",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[0].argmax())\n",
        "\n",
        "print(tensoring(x_train[0]).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD6AZcnKheBn",
        "outputId": "d4b173cd-1edc-4cea-f4de-9a3d687d207d"
      },
      "id": "OD6AZcnKheBn",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29\n",
            "torch.Size([3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "def train_loop(model, x_train, y_train, epoch):\n",
        "  model = model\n",
        "  x_train = x_train\n",
        "  y_train = y_train\n",
        "\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  predict_list = []\n",
        "\n",
        "  \n",
        "  total_count = 0\n",
        "  num_correct = 0\n",
        "  current_loss = 0\n",
        "\n",
        "  for idx, img in enumerate(x_train):\n",
        "      tense = tensoring(img)\n",
        "      \n",
        "      prediction = model.forward(tense)\n",
        "      print(prediction.shape)\n",
        "      #print('predict',prediction, 'predict')\n",
        "      #print('max', prediction.argmax())\n",
        "    \n",
        "      label = torch.tensor(y_train[idx])\n",
        "      #print('label', label)\n",
        "      label = label.to(torch.float32)\n",
        "\n",
        "      loss = loss_fn(prediction, label)\n",
        "      \n",
        "      predict_list.append(prediction.argmax())\n",
        "\n",
        "      \n",
        "\n",
        "      print('\\n ---------------------------------------------------------------')\n",
        "      print('             Epoch: ', epoch, '  Sample: ', idx)\n",
        "\n",
        "      if prediction.argmax() == label:\n",
        "          print('\\n ########################### HIT ########################### \\n')\n",
        "          num_correct +=1\n",
        "      else:\n",
        "        print('\\n ########################### MISS ########################### \\n')\n",
        "          \n",
        "      total_count+=1\n",
        "\n",
        "      print('Prediction: ', prediction,'ARRRGGGG', prediction.argmax())\n",
        "      print('Label: ',label)\n",
        "      print()\n",
        "      print('Loss: ', loss.item())\n",
        "      print()\n",
        "      print('---------------------------------------------------------------')\n",
        "      print(\" |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \")\n",
        "\n",
        "      current_loss += loss.item()\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "\n",
        "  return current_loss, predict_list, num_correct\n",
        "\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "JBGib0IC5Xcj"
      },
      "id": "JBGib0IC5Xcj",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validation loop\n",
        "\n",
        "def validation_loop(model, x_val, y_val, epoch):\n",
        "  model = model\n",
        "  x_val = x_val\n",
        "  y_val = y_val\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  predict_list = []\n",
        "  \n",
        "  total_count = 0\n",
        "  num_correct = 0\n",
        "  current_loss = 0\n",
        "  print(np.array(x_val).shape)\n",
        "  for idx, img in enumerate(x_val):\n",
        "      tense = tensoring(img)\n",
        "      \n",
        "      prediction = model.forward(tense)\n",
        "      print(prediction.shape)\n",
        "\n",
        "    \n",
        "      label = torch.tensor(y_train[idx])\n",
        "\n",
        "      label = label.to(torch.float32)\n",
        "\n",
        "      loss = loss_fn(prediction, label)\n",
        "      \n",
        "      predict_list.append(prediction.argmax())\n",
        "\n",
        "      \n",
        "\n",
        "      print('\\n ---------------------------------------------------------------')\n",
        "      print('             Epoch: ', epoch, '  Sample: ', idx)\n",
        "\n",
        "      if prediction.argmax() == label:\n",
        "          print('\\n ########################### HIT ########################### \\n')\n",
        "          num_correct +=1\n",
        "      else:\n",
        "        print('\\n ########################### MISS ########################### \\n')\n",
        "          \n",
        "      total_count+=1\n",
        "\n",
        "      print('Prediction: ', prediction,'ARRRGGGG', prediction.argmax())\n",
        "      print('Label: ',label)\n",
        "      print()\n",
        "      print('Loss: ', loss.item())\n",
        "      print()\n",
        "      print('---------------------------------------------------------------')\n",
        "      print(\" |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \")\n",
        "\n",
        "      current_loss += loss.item()\n",
        "\n",
        "\n",
        "  return current_loss, predict_list, num_correct\n",
        "\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "vGaIGgFsHw6j"
      },
      "id": "vGaIGgFsHw6j",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_loss_list = []\n",
        "t_predict_list =[]\n",
        "t_accuracy_list = []\n",
        "\n",
        "v_loss_list = []\n",
        "v_predict_list =[]\n",
        "v_accuracy_list = []\n",
        "\n",
        "total_epochs = 0"
      ],
      "metadata": {
        "id": "ZSIFZvu7J92C"
      },
      "id": "ZSIFZvu7J92C",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print('EPOCH: ', epoch)\n",
        "  print('----------------------')\n",
        "  print(' \\n                  TRAINING... \\n')\n",
        "  print('----------------------')\n",
        "  train_loss, train_predict_loss, train_num_correct = train_loop(model, x_train, y_train, epoch)\n",
        "  t_loss_list.append(train_loss)\n",
        "  t_predict_list.append(train_predict_loss)\n",
        "  t_accuracy_list.append(train_num_correct / len(y_train))\n",
        "\n",
        "\n",
        "  print('----------------------')\n",
        "  print(' \\n                  VALIDATION... \\n')\n",
        "  print('----------------------')\n",
        "  val_loss, val_predict_loss, val_num_correct = validation_loop(model, x_val, y_val, epoch)\n",
        "  v_loss_list.append(val_loss)\n",
        "  v_predict_list.append(val_predict_loss)\n",
        "  v_accuracy_list.append(val_num_correct/ len(y_val))\n",
        "\n",
        "  total_epochs +=1\n"
      ],
      "metadata": {
        "id": "bgIIZsVIKo5X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43eddb13-de1c-4f91-9a87-b28e1e559f9d"
      },
      "id": "bgIIZsVIKo5X",
      "execution_count": 41,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH:  0\n",
            "----------------------\n",
            " \n",
            "                  TRAINING... \n",
            "\n",
            "----------------------\n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  0   Sample:  0\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0206, 0.0046, 0.0298, 0.0000, 0.0000, 0.0195, 0.0000, 0.0213,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.0002164777397410944\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  0   Sample:  1\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0174, 0.0060, 0.0232, 0.0000, 0.0000, 0.0157, 0.0000, 0.0177,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.88819122314453\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  0   Sample:  2\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0202, 0.0000, 0.0228, 0.0024, 0.0000, 0.0100, 0.0000, 0.0087,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.935958862304688\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  0   Sample:  3\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0200, 0.0089, 0.0260, 0.0000, 0.0000, 0.0142, 0.0000, 0.0210,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.910123825073242\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  0   Sample:  4\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0173, 0.0051, 0.0246, 0.0000, 0.0000, 0.0149, 0.0000, 0.0151,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.87700271606445\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  0   Sample:  5\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0207, 0.0071, 0.0134, 0.0000, 0.0000, 0.0119, 0.0000, 0.0147,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.91874313354492\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  0   Sample:  6\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0159, 0.0054, 0.0274, 0.0000, 0.0000, 0.0162, 0.0000, 0.0201,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.86412811279297\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  0   Sample:  7\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0223, 0.0064, 0.0231, 0.0000, 0.0000, 0.0177, 0.0000, 0.0246,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.0001988424191949889\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  0   Sample:  8\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0224, 0.0129, 0.0281, 0.0000, 0.0005, 0.0204, 0.0000, 0.0238,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.913775444030762\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  0   Sample:  9\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0134, 0.0033, 0.0291, 0.0013, 0.0000, 0.0180, 0.0000, 0.0177,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.884246826171875\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  0   Sample:  10\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0195, 0.0032, 0.0278, 0.0000, 0.0000, 0.0130, 0.0000, 0.0231,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.965562105178833\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  0   Sample:  11\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0128, 0.0204, 0.0247, 0.0000, 0.0000, 0.0131, 0.0018, 0.0285,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.898983001708984\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  0   Sample:  12\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0127, 0.0076, 0.0278, 0.0000, 0.0000, 0.0160, 0.0000, 0.0240,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.87688064575195\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  0   Sample:  13\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0173, 0.0000, 0.0240, 0.0002, 0.0000, 0.0138, 0.0000, 0.0169,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9856734275817871\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  0   Sample:  14\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0264, 0.0192, 0.0234, 0.0000, 0.0000, 0.0147, 0.0000, 0.0223,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.851829528808594\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  0   Sample:  15\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0184, 0.0052, 0.0159, 0.0111, 0.0000, 0.0198, 0.0000, 0.0208,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.90896987915039\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  0   Sample:  16\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0077, 0.0197, 0.0199, 0.0031, 0.0000, 0.0186, 0.0000, 0.0352,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4667\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0203, 0.0054, 0.0238, 0.0000, 0.0000, 0.0178, 0.0000, 0.0234,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.90943717956543\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4668\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0214, 0.0181, 0.0183, 0.0000, 0.0000, 0.0033, 0.0005, 0.0214,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9835637807846069\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4669\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0184, 0.0017, 0.0322, 0.0000, 0.0000, 0.0282, 0.0000, 0.0284,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.80436706542969\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4670\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0173, 0.0000, 0.0281, 0.0000, 0.0000, 0.0171, 0.0000, 0.0212,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.949942588806152\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4671\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0159, 0.0091, 0.0264, 0.0005, 0.0000, 0.0174, 0.0000, 0.0186,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.87714385986328\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4672\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0225, 0.0076, 0.0299, 0.0000, 0.0000, 0.0200, 0.0000, 0.0201,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.940134048461914\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4673\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0222, 0.0110, 0.0310, 0.0000, 0.0000, 0.0135, 0.0031, 0.0158,\n",
            "        0.0021], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.980451762676239\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4674\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0171, 0.0028, 0.0111, 0.0068, 0.0000, 0.0209, 0.0000, 0.0000,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.917938232421875\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4675\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0173, 0.0055, 0.0280, 0.0000, 0.0000, 0.0102, 0.0000, 0.0220,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.0001700684952083975\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4676\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0191, 0.0040, 0.0283, 0.0000, 0.0000, 0.0185, 0.0000, 0.0173,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.8607177734375\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4677\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0215, 0.0013, 0.0224, 0.0000, 0.0000, 0.0164, 0.0000, 0.0180,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.000156016816617921\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4678\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0193, 0.0103, 0.0222, 0.0000, 0.0000, 0.0104, 0.0000, 0.0304,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.9631760120391846\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4679\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0117, 0.0026, 0.0231, 0.0048, 0.0000, 0.0152, 0.0000, 0.0156,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.86868286132812\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4680\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0135, 0.0000, 0.0179, 0.0003, 0.0000, 0.0103, 0.0000, 0.0000,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  6.1024991737212986e-05\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4681\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0199, 0.0043, 0.0260, 0.0006, 0.0000, 0.0176, 0.0000, 0.0145,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.8510513305664\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4682\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0130, 0.0029, 0.0212, 0.0000, 0.0000, 0.0118, 0.0000, 0.0202,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9863071441650391\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4683\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0083, 0.0119, 0.0209, 0.0006, 0.0000, 0.0000, 0.0000, 0.0085,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.9195556640625\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4684\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0182, 0.0017, 0.0225, 0.0000, 0.0000, 0.0209, 0.0000, 0.0074,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.901145935058594\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4685\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0165, 0.0004, 0.0261, 0.0006, 0.0000, 0.0229, 0.0000, 0.0204,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9828212857246399\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4686\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0217, 0.0014, 0.0190, 0.0055, 0.0000, 0.0128, 0.0000, 0.0151,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.939641952514648\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4687\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0041, 0.0000, 0.0108, 0.0006, 0.0032, 0.0274, 0.0000, 0.0253,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.943061828613281\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4688\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0145, 0.0033, 0.0277, 0.0000, 0.0000, 0.0164, 0.0000, 0.0203,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.950810432434082\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4689\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0041, 0.0110, 0.0310, 0.0065, 0.0008, 0.0126, 0.0000, 0.0268,\n",
            "        0.0072], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.88019561767578\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4690\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0150, 0.0103, 0.0309, 0.0000, 0.0005, 0.0252, 0.0000, 0.0247,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.0002525394083932042\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4691\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0206, 0.0000, 0.0205, 0.0000, 0.0000, 0.0230, 0.0000, 0.0178,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.90190887451172\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4692\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0193, 0.0076, 0.0281, 0.0000, 0.0000, 0.0152, 0.0000, 0.0187,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.964632749557495\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4693\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0157, 0.0051, 0.0181, 0.0000, 0.0000, 0.0129, 0.0000, 0.0138,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.88218688964844\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4694\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0220, 0.0101, 0.0311, 0.0027, 0.0000, 0.0224, 0.0000, 0.0217,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.84630584716797\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4695\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0190, 0.0183, 0.0185, 0.0018, 0.0000, 0.0155, 0.0000, 0.0181,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.9636878967285156\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4696\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0175, 0.0000, 0.0174, 0.0037, 0.0000, 0.0200, 0.0000, 0.0229,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.0001544053084217012\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4697\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0095, 0.0013, 0.0233, 0.0000, 0.0000, 0.0234, 0.0000, 0.0171,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.92557144165039\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4698\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0132, 0.0107, 0.0309, 0.0000, 0.0000, 0.0157, 0.0000, 0.0265,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9808224439620972\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4699\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0161, 0.0000, 0.0308, 0.0072, 0.0000, 0.0201, 0.0000, 0.0116,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.880027770996094\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4700\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0189, 0.0046, 0.0300, 0.0005, 0.0000, 0.0123, 0.0000, 0.0156,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.934640884399414\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4701\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0180, 0.0071, 0.0180, 0.0000, 0.0000, 0.0168, 0.0000, 0.0148,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.00011984720913460478\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4702\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0207, 0.0048, 0.0209, 0.0000, 0.0000, 0.0140, 0.0000, 0.0193,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.968259334564209\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4703\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0098, 0.0149, 0.0209, 0.0000, 0.0000, 0.0106, 0.0000, 0.0208,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.861572265625\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4704\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0105, 0.0000, 0.0240, 0.0000, 0.0000, 0.0194, 0.0000, 0.0281,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.85242462158203\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4705\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0195, 0.0060, 0.0275, 0.0000, 0.0000, 0.0159, 0.0000, 0.0214,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.85573196411133\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4706\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0208, 0.0000, 0.0236, 0.0003, 0.0000, 0.0098, 0.0000, 0.0124,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.9733452796936035\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4707\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0232, 0.0016, 0.0249, 0.0071, 0.0000, 0.0269, 0.0000, 0.0222,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.936681747436523\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4708\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0164, 0.0062, 0.0236, 0.0043, 0.0000, 0.0180, 0.0000, 0.0218,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.89194107055664\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4709\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0152, 0.0083, 0.0219, 0.0006, 0.0000, 0.0224, 0.0000, 0.0210,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.857154846191406\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4710\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0220, 0.0060, 0.0308, 0.0000, 0.0000, 0.0206, 0.0000, 0.0247,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.833763122558594\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4711\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0072, 0.0000, 0.0215, 0.0046, 0.0000, 0.0120, 0.0000, 0.0207,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9869000315666199\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4712\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0185, 0.0005, 0.0244, 0.0000, 0.0029, 0.0258, 0.0000, 0.0279,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.940216064453125\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4713\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0171, 0.0034, 0.0279, 0.0040, 0.0000, 0.0283, 0.0000, 0.0354,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.953843593597412\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4714\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0123, 0.0117, 0.0306, 0.0000, 0.0000, 0.0169, 0.0000, 0.0202,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.00019159606017637998\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4715\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0116, 0.0129, 0.0271, 0.0000, 0.0000, 0.0045, 0.0000, 0.0209,\n",
            "        0.0005], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.9691615104675293\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4716\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0091, 0.0000, 0.0320, 0.0000, 0.0000, 0.0067, 0.0000, 0.0134,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.914283752441406\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4717\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0177, 0.0026, 0.0270, 0.0007, 0.0000, 0.0033, 0.0000, 0.0183,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.8748779296875\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4718\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0145, 0.0019, 0.0222, 0.0010, 0.0000, 0.0182, 0.0000, 0.0192,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.907814025878906\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4719\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0184, 0.0032, 0.0218, 0.0051, 0.0000, 0.0183, 0.0000, 0.0116,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.937434196472168\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4720\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0138, 0.0000, 0.0253, 0.0020, 0.0000, 0.0136, 0.0000, 0.0083,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.962308883666992\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4721\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0197, 0.0084, 0.0266, 0.0003, 0.0000, 0.0167, 0.0000, 0.0187,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.87358474731445\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4722\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0152, 0.0025, 0.0243, 0.0000, 0.0000, 0.0163, 0.0000, 0.0168,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9851289987564087\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4723\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0161, 0.0033, 0.0331, 0.0000, 0.0000, 0.0107, 0.0000, 0.0100,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.926952362060547\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4724\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0121, 0.0075, 0.0127, 0.0037, 0.0000, 0.0203, 0.0000, 0.0211,\n",
            "        0.0033], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.903350830078125\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4725\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0184, 0.0060, 0.0241, 0.0000, 0.0000, 0.0178, 0.0000, 0.0204,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.89617919921875\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4726\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0300, 0.0000, 0.0253, 0.0000, 0.0000, 0.0136, 0.0000, 0.0238,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.963181734085083\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4727\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0244, 0.0000, 0.0220, 0.0108, 0.0000, 0.0189, 0.0000, 0.0241,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.839881896972656\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4728\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0240, 0.0000, 0.0154, 0.0000, 0.0000, 0.0167, 0.0000, 0.0172,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.86825561523438\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4729\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0204, 0.0111, 0.0246, 0.0025, 0.0000, 0.0176, 0.0000, 0.0165,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.963104724884033\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4730\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0210, 0.0056, 0.0238, 0.0039, 0.0000, 0.0154, 0.0000, 0.0223,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.945022583007812\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4731\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0213, 0.0038, 0.0273, 0.0000, 0.0000, 0.0170, 0.0000, 0.0181,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.947661399841309\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4732\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0144, 0.0000, 0.0234, 0.0000, 0.0000, 0.0135, 0.0000, 0.0232,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.8958854675293\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4733\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0138, 0.0000, 0.0263, 0.0010, 0.0000, 0.0182, 0.0000, 0.0094,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9863882064819336\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4734\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0131, 0.0082, 0.0209, 0.0000, 0.0000, 0.0332, 0.0000, 0.0329,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.848541259765625\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4735\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0170, 0.0154, 0.0274, 0.0000, 0.0000, 0.0225, 0.0000, 0.0186,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.939626693725586\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4736\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0090, 0.0000, 0.0230, 0.0015, 0.0000, 0.0080, 0.0000, 0.0196,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.951252937316895\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4737\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0166, 0.0047, 0.0114, 0.0236, 0.0000, 0.0347, 0.0000, 0.0173,\n",
            "        0.0076], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.8610954284668\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4738\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0240, 0.0056, 0.0219, 0.0000, 0.0000, 0.0152, 0.0000, 0.0226,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.9108943939209\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4739\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0170, 0.0086, 0.0249, 0.0000, 0.0000, 0.0172, 0.0000, 0.0194,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.878231048583984\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4740\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0245, 0.0088, 0.0145, 0.0021, 0.0000, 0.0235, 0.0000, 0.0286,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9798285365104675\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4741\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0151, 0.0015, 0.0194, 0.0052, 0.0000, 0.0167, 0.0000, 0.0225,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.90365219116211\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4742\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0230, 0.0000, 0.0232, 0.0000, 0.0000, 0.0118, 0.0000, 0.0228,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.91939353942871\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4743\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0235, 0.0056, 0.0240, 0.0000, 0.0000, 0.0152, 0.0004, 0.0238,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.926279067993164\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4744\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0160, 0.0053, 0.0250, 0.0003, 0.0000, 0.0209, 0.0000, 0.0215,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.946741104125977\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4745\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0184, 0.0067, 0.0203, 0.0071, 0.0000, 0.0118, 0.0000, 0.0214,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.948701858520508\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4746\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0190, 0.0000, 0.0243, 0.0000, 0.0000, 0.0138, 0.0000, 0.0215,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.89019012451172\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4747\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0208, 0.0041, 0.0242, 0.0000, 0.0000, 0.0084, 0.0000, 0.0203,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.922330856323242\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4748\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0149, 0.0255, 0.0289, 0.0000, 0.0000, 0.0211, 0.0008, 0.0314,\n",
            "        0.0020], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.82587432861328\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4749\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0228, 0.0083, 0.0271, 0.0000, 0.0000, 0.0119, 0.0000, 0.0204,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.00018830476619768888\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4750\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0252, 0.0000, 0.0265, 0.0060, 0.0000, 0.0147, 0.0000, 0.0203,\n",
            "        0.0010], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.00019981378864031285\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4751\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0166, 0.0004, 0.0251, 0.0000, 0.0000, 0.0076, 0.0000, 0.0126,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.937808990478516\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4752\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0324, 0.0133, 0.0183, 0.0000, 0.0000, 0.0167, 0.0066, 0.0077,\n",
            "        0.0015], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.845863342285156\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4753\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0290, 0.0340, 0.0197, 0.0130, 0.0000, 0.0250, 0.0000, 0.0170,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(2)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.890149116516113\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4754\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0171, 0.0000, 0.0189, 0.0000, 0.0000, 0.0233, 0.0000, 0.0233,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.917449951171875\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4755\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0148, 0.0140, 0.0165, 0.0068, 0.0000, 0.0287, 0.0000, 0.0235,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.85421371459961\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4756\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0175, 0.0128, 0.0250, 0.0000, 0.0000, 0.0187, 0.0000, 0.0188,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.9630579948425293\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4757\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0180, 0.0091, 0.0251, 0.0056, 0.0000, 0.0153, 0.0000, 0.0239,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.94206428527832\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4758\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0190, 0.0076, 0.0260, 0.0000, 0.0000, 0.0147, 0.0000, 0.0210,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.9648215770721436\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4759\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0165, 0.0021, 0.0279, 0.0000, 0.0000, 0.0160, 0.0000, 0.0187,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.00016619493544567376\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4760\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0214, 0.0124, 0.0354, 0.0000, 0.0000, 0.0156, 0.0000, 0.0238,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.9568028450012207\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4761\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0302, 0.0077, 0.0238, 0.0000, 0.0000, 0.0164, 0.0000, 0.0172,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.866798400878906\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4762\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0128, 0.0098, 0.0186, 0.0000, 0.0000, 0.0196, 0.0000, 0.0162,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9847204089164734\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4763\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0131, 0.0094, 0.0122, 0.0039, 0.0000, 0.0185, 0.0000, 0.0082,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.908695220947266\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4764\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0093, 0.0000, 0.0267, 0.0000, 0.0000, 0.0116, 0.0000, 0.0103,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9885034561157227\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4765\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0131, 0.0000, 0.0187, 0.0000, 0.0000, 0.0179, 0.0000, 0.0203,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.9161262512207\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4766\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0273, 0.0036, 0.0151, 0.0000, 0.0000, 0.0208, 0.0000, 0.0232,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.892208099365234\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4767\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0185, 0.0069, 0.0268, 0.0000, 0.0000, 0.0140, 0.0000, 0.0189,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.897911071777344\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4768\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0177, 0.0078, 0.0271, 0.0000, 0.0000, 0.0157, 0.0000, 0.0244,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.907485961914062\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4769\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0145, 0.0178, 0.0327, 0.0000, 0.0000, 0.0277, 0.0000, 0.0085,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.838417053222656\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4770\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0160, 0.0031, 0.0285, 0.0000, 0.0012, 0.0182, 0.0000, 0.0194,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.9138126373291\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4771\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0202, 0.0025, 0.0259, 0.0036, 0.0000, 0.0155, 0.0000, 0.0180,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.88025665283203\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4772\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0064, 0.0000, 0.0248, 0.0000, 0.0000, 0.0078, 0.0000, 0.0241,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.9748992919921875\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4773\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0190, 0.0055, 0.0282, 0.0098, 0.0000, 0.0164, 0.0000, 0.0189,\n",
            "        0.0085], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.87279510498047\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4774\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0141, 0.0030, 0.0231, 0.0000, 0.0000, 0.0157, 0.0006, 0.0262,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.8511962890625\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4775\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0184, 0.0075, 0.0168, 0.0015, 0.0000, 0.0093, 0.0000, 0.0208,\n",
            "        0.0005], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.955268859863281\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4776\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0227, 0.0115, 0.0179, 0.0061, 0.0102, 0.0254, 0.0000, 0.0194,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9775813221931458\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4777\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0254, 0.0091, 0.0267, 0.0023, 0.0000, 0.0100, 0.0000, 0.0230,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.942327499389648\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4778\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0223, 0.0000, 0.0190, 0.0012, 0.0000, 0.0227, 0.0000, 0.0235,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.84062194824219\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4779\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0227, 0.0048, 0.0259, 0.0013, 0.0000, 0.0230, 0.0000, 0.0198,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.86387252807617\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4780\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0054, 0.0104, 0.0243, 0.0066, 0.0000, 0.0284, 0.0000, 0.0170,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.944957733154297\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4781\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0222, 0.0000, 0.0282, 0.0000, 0.0000, 0.0200, 0.0000, 0.0171,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.947685241699219\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4782\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0124, 0.0000, 0.0055, 0.0143, 0.0000, 0.0236, 0.0000, 0.0168,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.956558227539062\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4783\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0106, 0.0062, 0.0258, 0.0000, 0.0000, 0.0105, 0.0000, 0.0376,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.0002340686332900077\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4784\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0188, 0.0104, 0.0163, 0.0000, 0.0000, 0.0143, 0.0020, 0.0162,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.875328063964844\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4785\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0147, 0.0040, 0.0259, 0.0019, 0.0000, 0.0194, 0.0000, 0.0166,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.85143280029297\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4786\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0225, 0.0004, 0.0275, 0.0000, 0.0001, 0.0345, 0.0000, 0.0214,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.83002471923828\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4787\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0141, 0.0125, 0.0271, 0.0000, 0.0000, 0.0215, 0.0000, 0.0199,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.00019481229537632316\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4788\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0232, 0.0054, 0.0192, 0.0010, 0.0000, 0.0147, 0.0004, 0.0215,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.948858261108398\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4789\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0212, 0.0095, 0.0259, 0.0000, 0.0000, 0.0174, 0.0000, 0.0205,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.943514823913574\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4790\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0186, 0.0009, 0.0225, 0.0000, 0.0000, 0.0075, 0.0000, 0.0176,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.90642166137695\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4791\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0106, 0.0080, 0.0170, 0.0000, 0.0000, 0.0099, 0.0021, 0.0247,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.0001181191619252786\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4792\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0097, 0.0040, 0.0273, 0.0032, 0.0000, 0.0195, 0.0000, 0.0201,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.84950256347656\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4793\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0166, 0.0000, 0.0180, 0.0024, 0.0000, 0.0222, 0.0000, 0.0336,\n",
            "        0.0064], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.86151123046875\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4794\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0198, 0.0040, 0.0157, 0.0000, 0.0000, 0.0198, 0.0000, 0.0135,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.94188117980957\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4795\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0147, 0.0016, 0.0254, 0.0000, 0.0000, 0.0053, 0.0000, 0.0166,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.9746203422546387\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4796\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0194, 0.0043, 0.0239, 0.0014, 0.0000, 0.0274, 0.0000, 0.0164,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.83341979980469\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4797\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0149, 0.0103, 0.0242, 0.0000, 0.0000, 0.0128, 0.0065, 0.0198,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.911666870117188\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4798\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0239, 0.0117, 0.0260, 0.0019, 0.0000, 0.0178, 0.0000, 0.0160,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.922431945800781\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4799\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000e+00, 1.8941e-02, 0.0000e+00, 2.5118e-02, 5.1811e-05, 0.0000e+00,\n",
            "        3.5929e-03, 0.0000e+00, 1.5310e-02, 0.0000e+00],\n",
            "       grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.00012370035983622074\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4800\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0190, 0.0010, 0.0213, 0.0000, 0.0000, 0.0107, 0.0000, 0.0143,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.907447814941406\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4801\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0186, 0.0063, 0.0256, 0.0000, 0.0019, 0.0150, 0.0000, 0.0277,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.905088424682617\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4802\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0242, 0.0079, 0.0185, 0.0000, 0.0000, 0.0134, 0.0000, 0.0141,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9845099449157715\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4803\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0130, 0.0000, 0.0323, 0.0000, 0.0000, 0.0234, 0.0000, 0.0145,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.85054016113281\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4804\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0186, 0.0019, 0.0323, 0.0000, 0.0000, 0.0236, 0.0000, 0.0284,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.9583072662353516\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4805\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0134, 0.0000, 0.0274, 0.0000, 0.0000, 0.0105, 0.0000, 0.0243,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.954797744750977\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4806\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0156, 0.0123, 0.0340, 0.0000, 0.0000, 0.0033, 0.0025, 0.0201,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.0001971625752048567\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4807\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0218, 0.0062, 0.0209, 0.0000, 0.0000, 0.0137, 0.0000, 0.0208,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.90007019042969\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4808\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0199, 0.0000, 0.0268, 0.0000, 0.0000, 0.0165, 0.0000, 0.0236,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.965453624725342\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4809\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0165, 0.0064, 0.0230, 0.0026, 0.0000, 0.0107, 0.0000, 0.0126,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9857324361801147\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4810\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0182, 0.0000, 0.0192, 0.0024, 0.0007, 0.0050, 0.0000, 0.0195,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.961103439331055\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4811\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0180, 0.0158, 0.0204, 0.0000, 0.0000, 0.0076, 0.0000, 0.0190,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.85490417480469\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4812\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0189, 0.0030, 0.0159, 0.0000, 0.0000, 0.0226, 0.0000, 0.0119,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.9278507232666\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4813\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0189, 0.0147, 0.0149, 0.0000, 0.0000, 0.0122, 0.0000, 0.0279,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.87632751464844\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4814\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0217, 0.0083, 0.0293, 0.0000, 0.0000, 0.0182, 0.0000, 0.0212,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.88180160522461\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4815\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0181, 0.0095, 0.0261, 0.0000, 0.0000, 0.0114, 0.0000, 0.0188,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.9665889739990234\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4816\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0166, 0.0000, 0.0271, 0.0008, 0.0000, 0.0168, 0.0000, 0.0206,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.885372161865234\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4817\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0302, 0.0000, 0.0252, 0.0051, 0.0008, 0.0162, 0.0000, 0.0183,\n",
            "        0.0003], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.88496398925781\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4818\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0141, 0.0000, 0.0243, 0.0000, 0.0000, 0.0100, 0.0000, 0.0181,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9868282079696655\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4819\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0191, 0.0000, 0.0256, 0.0000, 0.0000, 0.0229, 0.0000, 0.0207,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.91181755065918\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4820\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0210, 0.0000, 0.0270, 0.0000, 0.0000, 0.0215, 0.0000, 0.0210,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.945943832397461\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4821\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0199, 0.0106, 0.0266, 0.0000, 0.0000, 0.0116, 0.0002, 0.0262,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.905071258544922\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4822\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0273, 0.0108, 0.0202, 0.0000, 0.0000, 0.0287, 0.0008, 0.0235,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9780011177062988\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4823\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0228, 0.0072, 0.0297, 0.0000, 0.0000, 0.0163, 0.0000, 0.0195,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.866477966308594\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4824\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0135, 0.0000, 0.0257, 0.0000, 0.0000, 0.0040, 0.0000, 0.0297,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.941813468933105\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4825\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0151, 0.0114, 0.0225, 0.0000, 0.0000, 0.0094, 0.0000, 0.0247,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.966909408569336\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4826\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0195, 0.0000, 0.0183, 0.0006, 0.0000, 0.0120, 0.0000, 0.0150,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.89543533325195\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4827\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0190, 0.0059, 0.0131, 0.0096, 0.0000, 0.0101, 0.0000, 0.0074,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.89603805541992\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4828\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0035, 0.0212, 0.0285, 0.0000, 0.0000, 0.0034, 0.0001, 0.0254,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.918071746826172\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4829\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0230, 0.0000, 0.0217, 0.0000, 0.0000, 0.0127, 0.0000, 0.0221,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.9683773517608643\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4830\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0195, 0.0024, 0.0271, 0.0000, 0.0000, 0.0230, 0.0000, 0.0189,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.927450180053711\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4831\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0179, 0.0097, 0.0261, 0.0000, 0.0000, 0.0193, 0.0000, 0.0210,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.8310317993164\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4832\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0162, 0.0148, 0.0219, 0.0000, 0.0000, 0.0269, 0.0000, 0.0230,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.81495666503906\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4833\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0162, 0.0029, 0.0271, 0.0057, 0.0000, 0.0209, 0.0000, 0.0236,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.903743743896484\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4834\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0122, 0.0132, 0.0261, 0.0010, 0.0000, 0.0184, 0.0000, 0.0140,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.86425018310547\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4835\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0077, 0.0083, 0.0253, 0.0000, 0.0000, 0.0144, 0.0000, 0.0259,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.885948181152344\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4836\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0200, 0.0041, 0.0260, 0.0000, 0.0000, 0.0138, 0.0000, 0.0226,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.913724899291992\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4837\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0176, 0.0025, 0.0178, 0.0013, 0.0000, 0.0075, 0.0000, 0.0166,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  9.669167775427923e-05\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4838\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0175, 0.0132, 0.0160, 0.0131, 0.0000, 0.0196, 0.0000, 0.0194,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9803922772407532\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4839\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0135, 0.0072, 0.0200, 0.0025, 0.0000, 0.0263, 0.0000, 0.0269,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.903791427612305\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4840\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0248, 0.0000, 0.0233, 0.0014, 0.0000, 0.0138, 0.0000, 0.0153,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9844457507133484\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4841\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0177, 0.0211, 0.0223, 0.0000, 0.0000, 0.0020, 0.0000, 0.0231,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.931159973144531\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4842\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0083, 0.0096, 0.0155, 0.0028, 0.0000, 0.0126, 0.0000, 0.0089,\n",
            "        0.0042], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.925933837890625\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4843\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0232, 0.0018, 0.0205, 0.0000, 0.0000, 0.0173, 0.0000, 0.0186,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.935063362121582\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4844\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0092, 0.0223, 0.0292, 0.0096, 0.0000, 0.0277, 0.0000, 0.0211,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.905095100402832\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4845\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0256, 0.0018, 0.0208, 0.0000, 0.0000, 0.0170, 0.0000, 0.0194,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.864898681640625\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4846\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0154, 0.0022, 0.0150, 0.0128, 0.0000, 0.0076, 0.0000, 0.0139,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.959941864013672\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4847\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0223, 0.0000, 0.0250, 0.0091, 0.0000, 0.0197, 0.0000, 0.0131,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9823541641235352\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4848\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0181, 0.0130, 0.0179, 0.0000, 0.0000, 0.0181, 0.0000, 0.0170,\n",
            "        0.0064], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.945816040039062\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4849\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0167, 0.0000, 0.0245, 0.0000, 0.0000, 0.0109, 0.0000, 0.0132,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.9740138053894043\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4850\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0184, 0.0000, 0.0145, 0.0105, 0.0000, 0.0115, 0.0000, 0.0078,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9875537753105164\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4851\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0096, 0.0000, 0.0250, 0.0000, 0.0000, 0.0074, 0.0000, 0.0255,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9866254925727844\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4852\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0285, 0.0000, 0.0156, 0.0004, 0.0000, 0.0139, 0.0018, 0.0214,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.91849136352539\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4853\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0244, 0.0156, 0.0245, 0.0033, 0.0000, 0.0130, 0.0039, 0.0180,\n",
            "        0.0014], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.9586033821105957\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4854\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0229, 0.0000, 0.0281, 0.0000, 0.0000, 0.0198, 0.0000, 0.0174,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.947279930114746\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4855\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0185, 0.0036, 0.0238, 0.0000, 0.0000, 0.0190, 0.0000, 0.0186,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.966768741607666\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4856\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0194, 0.0045, 0.0260, 0.0000, 0.0000, 0.0180, 0.0000, 0.0185,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.931114196777344\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4857\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0100, 0.0000, 0.0218, 0.0000, 0.0000, 0.0000, 0.0000, 0.0173,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.931373596191406\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4858\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0117, 0.0018, 0.0227, 0.0000, 0.0000, 0.0222, 0.0000, 0.0220,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.95195484161377\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4859\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0212, 0.0058, 0.0246, 0.0000, 0.0000, 0.0137, 0.0000, 0.0177,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.00015843359869904816\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4860\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0208, 0.0035, 0.0228, 0.0022, 0.0000, 0.0143, 0.0000, 0.0201,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.9667134284973145\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4861\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0357, 0.0091, 0.0215, 0.0000, 0.0000, 0.0088, 0.0000, 0.0255,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9801355600357056\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4862\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0184, 0.0000, 0.0240, 0.0000, 0.0000, 0.0118, 0.0000, 0.0210,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.924894332885742\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4863\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0186, 0.0126, 0.0240, 0.0000, 0.0000, 0.0143, 0.0007, 0.0227,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.83296203613281\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4864\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0105, 0.0127, 0.0187, 0.0000, 0.0000, 0.0128, 0.0000, 0.0260,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.90338897705078\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4865\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0166, 0.0104, 0.0201, 0.0000, 0.0000, 0.0128, 0.0006, 0.0218,\n",
            "        0.0047], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.87826156616211\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4866\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0158, 0.0091, 0.0184, 0.0000, 0.0000, 0.0127, 0.0000, 0.0122,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.972837448120117\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4867\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0341, 0.0000, 0.0205, 0.0000, 0.0000, 0.0102, 0.0003, 0.0087,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.941136360168457\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4868\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0201, 0.0000, 0.0279, 0.0038, 0.0000, 0.0185, 0.0000, 0.0136,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.899513244628906\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4869\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0135, 0.0076, 0.0186, 0.0000, 0.0000, 0.0184, 0.0000, 0.0320,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.89203643798828\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4870\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0194, 0.0071, 0.0247, 0.0000, 0.0000, 0.0160, 0.0000, 0.0206,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.947507858276367\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4871\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0157, 0.0091, 0.0177, 0.0000, 0.0000, 0.0139, 0.0000, 0.0235,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.00013894190487917513\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4872\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0268, 0.0000, 0.0244, 0.0000, 0.0000, 0.0162, 0.0000, 0.0163,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.866249084472656\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4873\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0194, 0.0173, 0.0165, 0.0078, 0.0000, 0.0190, 0.0000, 0.0163,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.00016358462744392455\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4874\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0182, 0.0111, 0.0249, 0.0000, 0.0000, 0.0204, 0.0000, 0.0254,\n",
            "        0.0060], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.80949401855469\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4875\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0170, 0.0107, 0.0260, 0.0000, 0.0000, 0.0162, 0.0000, 0.0213,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.87248992919922\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4876\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0128, 0.0000, 0.0416, 0.0047, 0.0000, 0.0151, 0.0000, 0.0212,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.82850646972656\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4877\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0241, 0.0125, 0.0127, 0.0000, 0.0000, 0.0224, 0.0000, 0.0287,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.899831771850586\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4878\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0239, 0.0131, 0.0259, 0.0000, 0.0000, 0.0184, 0.0000, 0.0206,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.93909740447998\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4879\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0194, 0.0078, 0.0238, 0.0000, 0.0000, 0.0148, 0.0000, 0.0211,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.930625915527344\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4880\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0215, 0.0101, 0.0202, 0.0024, 0.0000, 0.0189, 0.0000, 0.0255,\n",
            "        0.0054], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.87544631958008\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4881\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0256, 0.0054, 0.0210, 0.0000, 0.0000, 0.0239, 0.0000, 0.0244,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.87981414794922\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4882\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0217, 0.0088, 0.0195, 0.0000, 0.0000, 0.0180, 0.0000, 0.0206,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.893898010253906\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4883\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0203, 0.0098, 0.0231, 0.0000, 0.0000, 0.0190, 0.0000, 0.0207,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.87010955810547\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4884\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0226, 0.0000, 0.0216, 0.0000, 0.0000, 0.0091, 0.0015, 0.0110,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.88175964355469\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4885\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0167, 0.0030, 0.0232, 0.0000, 0.0000, 0.0204, 0.0000, 0.0144,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9846075177192688\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4886\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0225, 0.0091, 0.0245, 0.0004, 0.0000, 0.0077, 0.0000, 0.0142,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9844784736633301\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4887\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0223, 0.0059, 0.0237, 0.0088, 0.0034, 0.0289, 0.0070, 0.0219,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.8051872253418\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4888\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0173, 0.0000, 0.0199, 0.0119, 0.0000, 0.0241, 0.0000, 0.0183,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.926908493041992\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4889\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0177, 0.0157, 0.0282, 0.0000, 0.0000, 0.0110, 0.0000, 0.0227,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.86664581298828\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4890\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0180, 0.0140, 0.0073, 0.0180, 0.0000, 0.0220, 0.0000, 0.0269,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.851722717285156\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4891\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0141, 0.0073, 0.0254, 0.0000, 0.0000, 0.0106, 0.0007, 0.0230,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.95147705078125\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4892\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0197, 0.0000, 0.0206, 0.0003, 0.0000, 0.0147, 0.0000, 0.0119,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.00011714769061654806\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4893\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0216, 0.0011, 0.0254, 0.0005, 0.0000, 0.0197, 0.0000, 0.0210,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.946669578552246\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4894\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0237, 0.0113, 0.0233, 0.0000, 0.0000, 0.0128, 0.0000, 0.0274,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.82289123535156\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4895\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0181, 0.0096, 0.0298, 0.0000, 0.0000, 0.0193, 0.0000, 0.0244,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.83843994140625\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4896\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0155, 0.0082, 0.0237, 0.0000, 0.0000, 0.0126, 0.0000, 0.0220,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.85263061523438\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4897\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0152, 0.0013, 0.0245, 0.0000, 0.0000, 0.0074, 0.0000, 0.0117,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.89190673828125\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4898\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0160, 0.0045, 0.0230, 0.0000, 0.0007, 0.0244, 0.0000, 0.0180,\n",
            "        0.0007], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.00017227741773240268\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4899\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0177, 0.0035, 0.0078, 0.0000, 0.0000, 0.0137, 0.0000, 0.0194,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.937952041625977\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4900\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0023, 0.0000, 0.0263, 0.0000, 0.0000, 0.0110, 0.0000, 0.0239,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.93667984008789\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4901\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0237, 0.0036, 0.0280, 0.0004, 0.0000, 0.0184, 0.0000, 0.0186,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.944572448730469\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4902\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0129, 0.0000, 0.0270, 0.0051, 0.0000, 0.0145, 0.0000, 0.0206,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.85623931884766\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4903\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0207, 0.0110, 0.0185, 0.0000, 0.0000, 0.0141, 0.0064, 0.0220,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.981623649597168\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4904\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0148, 0.0169, 0.0197, 0.0000, 0.0000, 0.0111, 0.0000, 0.0225,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.86405563354492\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4905\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0144, 0.0046, 0.0259, 0.0000, 0.0000, 0.0151, 0.0058, 0.0290,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.886619567871094\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4906\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0251, 0.0104, 0.0292, 0.0007, 0.0000, 0.0231, 0.0000, 0.0199,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.956869602203369\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4907\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0124, 0.0000, 0.0191, 0.0000, 0.0000, 0.0141, 0.0000, 0.0108,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  8.322812209371477e-05\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4908\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0173, 0.0070, 0.0262, 0.0000, 0.0000, 0.0176, 0.0000, 0.0188,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.861083984375\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4909\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0190, 0.0037, 0.0257, 0.0000, 0.0000, 0.0126, 0.0000, 0.0225,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.85000610351562\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4910\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0183, 0.0069, 0.0177, 0.0000, 0.0000, 0.0107, 0.0000, 0.0212,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.9252872467041\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4911\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0145, 0.0074, 0.0263, 0.0000, 0.0000, 0.0136, 0.0000, 0.0208,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.950621604919434\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4912\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0182, 0.0000, 0.0224, 0.0000, 0.0000, 0.0148, 0.0000, 0.0160,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.87162780761719\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4913\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0177, 0.0047, 0.0254, 0.0000, 0.0000, 0.0137, 0.0000, 0.0157,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9846956133842468\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4914\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0022, 0.0065, 0.0316, 0.0000, 0.0000, 0.0140, 0.0000, 0.0154,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9862316846847534\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4915\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0230, 0.0075, 0.0208, 0.0037, 0.0000, 0.0204, 0.0000, 0.0240,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9803237915039062\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4916\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0224, 0.0095, 0.0238, 0.0000, 0.0000, 0.0147, 0.0000, 0.0160,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.89628982543945\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4917\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0139, 0.0000, 0.0251, 0.0032, 0.0000, 0.0228, 0.0000, 0.0190,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.89936447143555\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4918\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0310, 0.0011, 0.0163, 0.0019, 0.0000, 0.0338, 0.0000, 0.0245,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.84823226928711\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4919\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0165, 0.0037, 0.0183, 0.0000, 0.0000, 0.0066, 0.0017, 0.0140,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9879010915756226\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4920\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0215, 0.0091, 0.0152, 0.0013, 0.0000, 0.0187, 0.0000, 0.0169,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.967008113861084\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4921\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0197, 0.0027, 0.0266, 0.0000, 0.0000, 0.0121, 0.0017, 0.0210,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.89963912963867\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4922\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0213, 0.0010, 0.0256, 0.0000, 0.0000, 0.0106, 0.0000, 0.0198,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9844964742660522\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4923\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0267, 0.0026, 0.0178, 0.0064, 0.0000, 0.0271, 0.0000, 0.0302,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.933774948120117\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4924\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0251, 0.0052, 0.0237, 0.0000, 0.0000, 0.0192, 0.0000, 0.0198,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.925764083862305\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4925\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0182, 0.0170, 0.0312, 0.0000, 0.0000, 0.0129, 0.0000, 0.0216,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9800200462341309\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4926\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0217, 0.0000, 0.0272, 0.0035, 0.0000, 0.0141, 0.0000, 0.0199,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.84465026855469\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4927\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0185, 0.0032, 0.0198, 0.0000, 0.0000, 0.0102, 0.0000, 0.0179,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.93043327331543\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4928\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0198, 0.0020, 0.0307, 0.0000, 0.0065, 0.0134, 0.0000, 0.0269,\n",
            "        0.0018], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.818359375\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4929\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0163, 0.0064, 0.0257, 0.0000, 0.0000, 0.0147, 0.0000, 0.0276,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.87310028076172\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4930\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000e+00, 2.2514e-02, 1.9923e-02, 1.6302e-02, 8.8965e-03, 0.0000e+00,\n",
            "        8.0206e-05, 4.1318e-03, 1.9616e-02, 0.0000e+00],\n",
            "       grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.945287704467773\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4931\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0167, 0.0079, 0.0272, 0.0000, 0.0000, 0.0190, 0.0000, 0.0223,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.9629719257354736\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4932\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0216, 0.0097, 0.0246, 0.0000, 0.0000, 0.0194, 0.0000, 0.0204,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.942777633666992\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4933\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0168, 0.0000, 0.0233, 0.0074, 0.0000, 0.0149, 0.0000, 0.0171,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.920726776123047\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4934\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0230, 0.0033, 0.0223, 0.0000, 0.0000, 0.0174, 0.0000, 0.0174,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.8834228515625\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4935\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0165, 0.0148, 0.0234, 0.0032, 0.0000, 0.0195, 0.0000, 0.0216,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.94078254699707\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4936\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0116, 0.0000, 0.0254, 0.0103, 0.0000, 0.0247, 0.0000, 0.0185,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.927815437316895\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4937\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0165, 0.0087, 0.0273, 0.0000, 0.0000, 0.0168, 0.0000, 0.0193,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.911535263061523\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4938\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0203, 0.0000, 0.0203, 0.0073, 0.0022, 0.0119, 0.0000, 0.0099,\n",
            "        0.0069], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.00011707001976901665\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4939\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0184, 0.0055, 0.0264, 0.0000, 0.0000, 0.0175, 0.0000, 0.0204,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.964876174926758\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4940\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0168, 0.0142, 0.0235, 0.0000, 0.0000, 0.0189, 0.0000, 0.0244,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.941437721252441\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4941\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0279, 0.0000, 0.0277, 0.0016, 0.0000, 0.0266, 0.0000, 0.0225,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.936437606811523\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4942\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0167, 0.0000, 0.0236, 0.0000, 0.0000, 0.0211, 0.0000, 0.0226,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.949747085571289\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4943\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0096, 0.0082, 0.0266, 0.0008, 0.0000, 0.0200, 0.0000, 0.0187,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.865943908691406\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4944\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0101, 0.0128, 0.0175, 0.0000, 0.0000, 0.0146, 0.0000, 0.0290,\n",
            "        0.0032], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.8428955078125\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4945\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0322, 0.0000, 0.0243, 0.0073, 0.0000, 0.0157, 0.0000, 0.0141,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.906707763671875\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4946\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0158, 0.0054, 0.0220, 0.0000, 0.0000, 0.0178, 0.0000, 0.0223,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.00015747678116895258\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4947\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0263, 0.0000, 0.0194, 0.0068, 0.0000, 0.0138, 0.0000, 0.0056,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.957077026367188\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4948\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0171, 0.0000, 0.0238, 0.0000, 0.0000, 0.0192, 0.0000, 0.0144,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.0001433934085071087\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4949\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0200, 0.0039, 0.0213, 0.0000, 0.0000, 0.0268, 0.0000, 0.0213,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.944258689880371\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4950\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0194, 0.0065, 0.0268, 0.0000, 0.0000, 0.0160, 0.0000, 0.0176,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.931062698364258\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4951\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0150, 0.0090, 0.0198, 0.0000, 0.0000, 0.0151, 0.0000, 0.0228,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.951155662536621\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4952\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0213, 0.0003, 0.0244, 0.0000, 0.0000, 0.0211, 0.0000, 0.0268,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.92510986328125\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4953\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0238, 0.0096, 0.0135, 0.0000, 0.0000, 0.0190, 0.0045, 0.0192,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.8748664855957\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4954\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0170, 0.0000, 0.0239, 0.0006, 0.0000, 0.0111, 0.0000, 0.0163,\n",
            "        0.0006], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.972304105758667\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4955\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0206, 0.0242, 0.0202, 0.0000, 0.0000, 0.0163, 0.0000, 0.0290,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.86785125732422\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4956\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0292, 0.0003, 0.0188, 0.0048, 0.0000, 0.0234, 0.0002, 0.0158,\n",
            "        0.0008], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9815319776535034\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4957\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0203, 0.0107, 0.0225, 0.0017, 0.0000, 0.0188, 0.0000, 0.0168,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.9638686180114746\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4958\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0204, 0.0172, 0.0259, 0.0000, 0.0000, 0.0224, 0.0000, 0.0254,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9780168533325195\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4959\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0085, 0.0000, 0.0196, 0.0000, 0.0000, 0.0112, 0.0000, 0.0220,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9878524541854858\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4960\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0134, 0.0005, 0.0281, 0.0000, 0.0000, 0.0125, 0.0000, 0.0239,\n",
            "        0.0042], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.85140228271484\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4961\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0227, 0.0049, 0.0207, 0.0070, 0.0000, 0.0205, 0.0000, 0.0185,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.962517261505127\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4962\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0191, 0.0000, 0.0230, 0.0000, 0.0000, 0.0196, 0.0111, 0.0120,\n",
            "        0.0020], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.8958854675293\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4963\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0186, 0.0000, 0.0227, 0.0002, 0.0000, 0.0111, 0.0000, 0.0115,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.94897747039795\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4964\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0202, 0.0073, 0.0315, 0.0037, 0.0000, 0.0247, 0.0000, 0.0144,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.857601165771484\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4965\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0289, 0.0035, 0.0186, 0.0000, 0.0000, 0.0126, 0.0000, 0.0124,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.00015071380767039955\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4966\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0199, 0.0130, 0.0263, 0.0000, 0.0000, 0.0143, 0.0000, 0.0238,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.86415100097656\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4967\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0254, 0.0000, 0.0264, 0.0000, 0.0073, 0.0180, 0.0000, 0.0233,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.93998908996582\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4968\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0235, 0.0000, 0.0153, 0.0069, 0.0000, 0.0126, 0.0000, 0.0195,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.9690184593200684\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4969\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0210, 0.0095, 0.0230, 0.0007, 0.0000, 0.0259, 0.0000, 0.0262,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.85148239135742\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4970\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0074, 0.0077, 0.0271, 0.0000, 0.0000, 0.0198, 0.0000, 0.0316,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.9628262519836426\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4971\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0216, 0.0065, 0.0273, 0.0000, 0.0000, 0.0156, 0.0000, 0.0188,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.928385734558105\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4972\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0223, 0.0000, 0.0306, 0.0088, 0.0000, 0.0049, 0.0025, 0.0108,\n",
            "        0.0002], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.92001724243164\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4973\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0249, 0.0053, 0.0308, 0.0000, 0.0000, 0.0058, 0.0000, 0.0157,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.88474655151367\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4974\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0162, 0.0144, 0.0207, 0.0000, 0.0000, 0.0184, 0.0000, 0.0279,\n",
            "        0.0056], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.85564041137695\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4975\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0171, 0.0000, 0.0276, 0.0000, 0.0000, 0.0103, 0.0000, 0.0202,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.00015718616486992687\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4976\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0245, 0.0000, 0.0233, 0.0015, 0.0011, 0.0198, 0.0000, 0.0153,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([4.])\n",
            "\n",
            "Loss:  15.931796073913574\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4977\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0204, 0.0044, 0.0253, 0.0000, 0.0000, 0.0064, 0.0000, 0.0150,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([1.])\n",
            "\n",
            "Loss:  0.9858503341674805\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4978\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0234, 0.0003, 0.0145, 0.0076, 0.0041, 0.0234, 0.0000, 0.0267,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.940248489379883\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4979\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0188, 0.0028, 0.0329, 0.0000, 0.0000, 0.0145, 0.0000, 0.0245,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.944134712219238\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4980\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0208, 0.0064, 0.0250, 0.0000, 0.0000, 0.0153, 0.0000, 0.0188,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.00016904580115806311\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4981\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0217, 0.0000, 0.0215, 0.0005, 0.0000, 0.0100, 0.0000, 0.0192,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.92721939086914\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4982\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0141, 0.0128, 0.0272, 0.0000, 0.0000, 0.0211, 0.0000, 0.0219,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.903057098388672\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4983\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0221, 0.0000, 0.0227, 0.0082, 0.0000, 0.0207, 0.0000, 0.0153,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.84010314941406\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4984\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0218, 0.0137, 0.0266, 0.0000, 0.0000, 0.0147, 0.0000, 0.0215,\n",
            "        0.0012], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.82115936279297\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4985\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0187, 0.0000, 0.0243, 0.0085, 0.0000, 0.0154, 0.0000, 0.0124,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.00014065504365134984\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4986\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0135, 0.0045, 0.0248, 0.0018, 0.0000, 0.0161, 0.0000, 0.0300,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.9638659954071045\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4987\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0130, 0.0020, 0.0233, 0.0000, 0.0000, 0.0114, 0.0000, 0.0172,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.893165588378906\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4988\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0232, 0.0040, 0.0239, 0.0000, 0.0000, 0.0208, 0.0000, 0.0266,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.960862398147583\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4989\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0194, 0.0060, 0.0145, 0.0000, 0.0054, 0.0183, 0.0017, 0.0285,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([2.])\n",
            "\n",
            "Loss:  3.962650775909424\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4990\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0165, 0.0090, 0.0286, 0.0000, 0.0000, 0.0165, 0.0000, 0.0207,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.90884780883789\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4991\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0193, 0.0000, 0.0236, 0.0003, 0.0000, 0.0196, 0.0000, 0.0170,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.88846206665039\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4992\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0198, 0.0000, 0.0319, 0.0000, 0.0000, 0.0158, 0.0000, 0.0226,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([5.])\n",
            "\n",
            "Loss:  24.90994644165039\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4993\n",
            "\n",
            " ########################### HIT ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0162, 0.0060, 0.0268, 0.0000, 0.0000, 0.0112, 0.0000, 0.0191,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([3.])\n",
            "\n",
            "Loss:  8.952638626098633\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4994\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0238, 0.0084, 0.0221, 0.0006, 0.0000, 0.0170, 0.0000, 0.0223,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(1)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.83079528808594\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4995\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0237, 0.0018, 0.0303, 0.0000, 0.0000, 0.0090, 0.0000, 0.0197,\n",
            "        0.0048], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([7.])\n",
            "\n",
            "Loss:  48.8751220703125\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4996\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0210, 0.0017, 0.0225, 0.0000, 0.0007, 0.0232, 0.0000, 0.0232,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(8)\n",
            "Label:  tensor([0.])\n",
            "\n",
            "Loss:  0.00020319715258665383\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4997\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0156, 0.0009, 0.0149, 0.0166, 0.0000, 0.0270, 0.0000, 0.0066,\n",
            "        0.0105], grad_fn=<ReluBackward0>) ARRRGGGG tensor(6)\n",
            "Label:  tensor([8.])\n",
            "\n",
            "Loss:  63.8526611328125\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4998\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0058, 0.0000, 0.0212, 0.0039, 0.0000, 0.0046, 0.0000, 0.0136,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([9.])\n",
            "\n",
            "Loss:  80.91183471679688\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n",
            "torch.Size([10])\n",
            "\n",
            " ---------------------------------------------------------------\n",
            "             Epoch:  9   Sample:  4999\n",
            "\n",
            " ########################### MISS ########################### \n",
            "\n",
            "Prediction:  tensor([0.0000, 0.0189, 0.0046, 0.0249, 0.0000, 0.0000, 0.0168, 0.0000, 0.0231,\n",
            "        0.0000], grad_fn=<ReluBackward0>) ARRRGGGG tensor(3)\n",
            "Label:  tensor([6.])\n",
            "\n",
            "Loss:  35.89422607421875\n",
            "\n",
            "---------------------------------------------------------------\n",
            " |||| ||||| ||||| ||||| ||||| ||||| |||| |||| ||||| |||| |||| \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import datetime\n",
        "execution = str(datetime.datetime.now())[0:19]\n",
        "print(\"Graphs created at: \",  execution)\n",
        "\n"
      ],
      "metadata": {
        "id": "u1w9Aq8M2NoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b76585d8-ef36-4be9-9ea3-56654d109d6a"
      },
      "id": "u1w9Aq8M2NoS",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Graphs created at:  2023-05-17 12:27:07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# learning curve\n",
        "def learning_curve(v_loss_list, t_loss_list):\n",
        "  plt.title(label=\"Learning Curve\", fontsize =30)\n",
        "  plt.plot(range(len(v_loss_list)), v_loss_list, label='Validation loss')\n",
        "  plt.plot(range(len(t_loss_list)), t_loss_list, label ='Training loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.savefig('/content/drive/MyDrive/cifar-10_basicmodel'+'_learningCuve'+str(total_epochs)+str(execution))\n",
        " \n",
        "def accuracy_curve(v_accuracy_list, t_accuracy_list):\n",
        "  plt.title(label=\"Accuracy Curve\", fontsize =30)\n",
        "  plt.plot(range(len(v_accuracy_list)), v_accuracy_list, label='Validation accuracy')\n",
        "  plt.plot(range(len(t_accuracy_list)), t_accuracy_list, label ='Training accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.savefig('/content/drive/MyDrive/cifar-10_basicmodel'+'_accuracyCuve'+str(total_epochs)+str(execution))\n",
        "\n",
        "learning_curve(v_loss_list, t_loss_list)\n",
        "\n",
        "accuracy_curve(v_accuracy_list, t_accuracy_list)"
      ],
      "metadata": {
        "id": "i6vUOjRi6243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 982
        },
        "outputId": "02a861e1-625f-4ac8-f72e-816ed4809f57"
      },
      "id": "i6vUOjRi6243",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RP9E5ZPEHvcz"
      },
      "id": "RP9E5ZPEHvcz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# functions from  https://machinelearningmastery.com/training-and-validation-data-in-pytorch/\n",
        "def plot_train_val_loss(train_err, val_err):\n",
        "  plt.semilogx(np.array(learning_rates), train_err.numpy(), label = 'total training loss')\n",
        "  plt.semilogx(np.array(learning_rates), val_err.numpy(), label = 'total validation loss')\n",
        "  plt.ylabel('Total Loss')\n",
        "  plt.xlabel('learning rate')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "# plotting the predictions on validation data\n",
        "def plot_predictions(model, learning_rate, x_val, val_prediction):\n",
        "  for model, learning_rate in zip(Models, learning_rates):\n",
        "      yhat = model(x_val)\n",
        "      plt.plot(x_val.numpy(), val_prediction.detach().numpy(), label = 'learning rate:' + str(learning_rate))\n",
        "  #plt.plot(x_val.numpy(), val_set.func.numpy(), 'or', label = 'validation data')\n",
        "  plt.xlabel('x')\n",
        "  plt.ylabel('y')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \"\"\""
      ],
      "metadata": {
        "id": "8-wmps08zOZj"
      },
      "id": "8-wmps08zOZj",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}